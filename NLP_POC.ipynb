{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data and consolidating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fileList=[]\n",
    "for fileIndex in xrange(1,6):\n",
    "    path='D:/Python Training/POC/Raw Data/CrawlerOutput_%i.csv'% (fileIndex)\n",
    "    fileList.append(pd.read_csv(path))\n",
    "    \n",
    "rawData=pd.concat(fileList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features=rawData.loc[:,['ArticleStory']]\n",
    "labels=rawData.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labEncoder=LabelEncoder()\n",
    "labelsEncoded=labEncoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning, Lemmatization, Tokenization, Stopwords, Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features=features.replace(np.nan,'')\n",
    "features['Cleaned']=features.ArticleStory.map(lambda row: re.sub('\\s+',' ',re.sub('[^a-z]', ' ',row.lower())).strip())\n",
    "\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "features['Lemmatized']=features.Cleaned.map(lambda row: ' '.join([lemmatizer.lemmatize(word) for word in row.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Breaking into train and test set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features.Lemmatized,labelsEncoded,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfIdfVect=TfidfVectorizer(stop_words=\"english\",ngram_range=(1,2),max_df=0.95,min_df=0.05)\n",
    "X_train=tfIdfVect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_transformed=tfIdfVect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Score =  0.761487964989\n"
     ]
    }
   ],
   "source": [
    "modelNB=MultinomialNB()\n",
    "modelNB=modelNB.fit(X_train,Y_train)\n",
    "\n",
    "#Scoring using test set\n",
    "print \"Naive Bayes Score = \",modelNB.score(X_test_transformed,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM with linear kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM Score =  0.910284463895\n"
     ]
    }
   ],
   "source": [
    "modelLinearSVM=SGDClassifier()\n",
    "modelLinearSVM=modelLinearSVM.fit(X_train,Y_train)\n",
    "\n",
    "#Scoring using test set\n",
    "print \"Linear SVM Score = \",modelLinearSVM.score(X_test_transformed,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Score =  0.901531728665\n"
     ]
    }
   ],
   "source": [
    "modelRandomForest=RandomForestClassifier(n_estimators=100)\n",
    "modelRandomForest=modelRandomForest.fit(X_train,Y_train)\n",
    "\n",
    "#Scoring using test set\n",
    "print \"Random Forest Score = \",modelRandomForest.score(X_test_transformed,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Score =  0.840262582057\n"
     ]
    }
   ],
   "source": [
    "modelLogistic=LogisticRegression()\n",
    "modelLogistic=modelLogistic.fit(X_train,Y_train)\n",
    "\n",
    "#Scoring using test set\n",
    "print \"Logistic Regression Score = \",modelLogistic.score(X_test_transformed,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Optimization (Grid Search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Score =  0.798687089716\n",
      "Best Parameters =  {'alpha': 0.2}\n"
     ]
    }
   ],
   "source": [
    "parametersNB={'alpha':(0,0.2,0.4,0.6,0.8,1)}\n",
    "gs_NB=GridSearchCV(modelNB,parametersNB,n_jobs=-1)\n",
    "gs_NB=gs_NB.fit(X_train,Y_train)\n",
    "\n",
    "#Scoring using test set\n",
    "print \"Naive Bayes Score = \",gs_NB.score(X_test_transformed,Y_test)\n",
    "print \"Best Parameters = \",gs_NB.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM with linear kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM Score =  0.901531728665\n",
      "Best Parameters =  {'penalty': 'l2', 'alpha': 0.0005, 'n_iter': 10, 'loss': 'modified_huber'}\n"
     ]
    }
   ],
   "source": [
    "parametersSVM={'loss':('hinge','log','modified_huber','perceptron'),\n",
    "              'penalty':('l1','l2'),\n",
    "              'alpha':(0.00005,0.0001,0.0005,0.001,0.005,0.01),\n",
    "              'n_iter':(1,5,10,50,100)}\n",
    "gs_SVM=GridSearchCV(modelLinearSVM,parametersSVM,n_jobs=-1)\n",
    "gs_SVM=gs_SVM.fit(X_train,Y_train)\n",
    "\n",
    "#Scoring using test set\n",
    "print \"Linear SVM Score = \",gs_SVM.score(X_test_transformed,Y_test)\n",
    "print \"Best Parameters = \",gs_SVM.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Score =  0.903719912473\n",
      "Best Parameters =  {'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "parametersRF={'n_estimators':(5,10,25,50,100,500,1000)}\n",
    "gs_RF=GridSearchCV(modelRandomForest,parametersRF,n_jobs=-1)\n",
    "gs_RF=gs_RF.fit(X_train,Y_train)\n",
    "\n",
    "#Scoring using test set\n",
    "print \"Random Forest Score = \",gs_RF.score(X_test_transformed,Y_test)\n",
    "print \"Best Parameters = \",gs_RF.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Score =  0.91466083151\n",
      "Best Parameters =  {'multi_class': 'ovr', 'C': 100, 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "parametersLogistic={'C':(0.01,0.1,1,10,100,1000),\n",
    "                   'solver':('newton-cg', 'lbfgs'),\n",
    "                   'multi_class':('multinomial','ovr')}\n",
    "gs_Logistic=GridSearchCV(modelLogistic,parametersLogistic,n_jobs=-1)\n",
    "gs_Logistic=gs_Logistic.fit(X_train,Y_train)\n",
    "\n",
    "#Scoring using test set\n",
    "print \"Logistic Regression Score = \",gs_Logistic.score(X_test_transformed,Y_test)\n",
    "print \"Best Parameters = \",gs_Logistic.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection (K-Fold Cross Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Consolidated features and label dataset\n",
    "X=tfIdfVect.fit_transform(features.Lemmatized)\n",
    "Y=labelsEncoded\n",
    "\n",
    "kfIter=KFold(n=X.shape[0],n_folds=5,shuffle=True,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Cross-Validation =  0.792804906138\n",
      "Linear SVM Cross-Validation =  0.911076240931\n",
      "Random Forest Cross-Validation =  0.912838304733\n",
      "Logistic Regression Cross-Validation =  0.910199047948\n"
     ]
    }
   ],
   "source": [
    "#Obtaining cross validation score for each model\n",
    "finalModelNB=MultinomialNB(alpha=0.2)\n",
    "print \"Naive Bayes Cross-Validation = \", np.mean(cross_val_score(finalModelNB,X,Y,cv=kfIter))\n",
    "\n",
    "finalModelSVM=SGDClassifier(penalty='l2',alpha=0.0005,n_iter=10,loss='modified_huber')\n",
    "print \"Linear SVM Cross-Validation = \", np.mean(cross_val_score(finalModelSVM,X,Y,cv=kfIter))\n",
    "\n",
    "finalModelRF=RandomForestClassifier(n_estimators=1000)\n",
    "print \"Random Forest Cross-Validation = \", np.mean(cross_val_score(finalModelRF,X,Y,cv=kfIter))\n",
    "\n",
    "finalModelLogistic=LogisticRegression(multi_class='ovr',C=100,solver='newton-cg')\n",
    "print \"Logistic Regression Cross-Validation = \", np.mean(cross_val_score(finalModelLogistic,X,Y,cv=kfIter))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
